{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loose-yemen",
   "metadata": {},
   "source": [
    "# Read mapping and depth (density) calculation\n",
    "\n",
    "for RNA-Seq/Ribo-Seq data of Kim et al. (SciData, 2020)\n",
    "- See [this notebook](../00-prep-pubdata/210615_expression_Kim+20SciData.ipynb) for procedures to download the data.\n",
    "\n",
    "- For both RNA- and Ribo-Seq, adapter sequences were automatically detected and trimmed from raw fastq reads by fastp (v0.20.1). Then bowtie2 (v2.4.4) was used to map the trimmed reads to the reference genomes. (The references were according to Kim et al.; see [metadata](../../metadata/expression/Kim+20SciData_refs.tsv)). Both tools was executed under the default parameters.\n",
    "\n",
    "- For RNA-Seq, position-wise read depths were counted, ignoring multi-mapped reads and reads that mapped to tRNA/rRNA on the same strand.\n",
    "- For Ribo-Seq, position-wise ribosome read densities were calculated by assigning reads to the regions from the 3' end positions to 27 bp upstream. Multi-mapped reads and reads that mapped to tRNA/rRNA on same strand were also removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-wilson",
   "metadata": {},
   "source": [
    "## Docker condifuration\n",
    "\n",
    "docker-compose.yml\n",
    "```\n",
    "version: '3'\n",
    "services:\n",
    "  (...)\n",
    "  mapping:\n",
    "    build: ./docker/mapping\n",
    "    volumes:\n",
    "      - ./data:/data\n",
    "      - ./metadata:/metadata\n",
    "      - ./scripts:/scripts\n",
    "  (...)\n",
    "```\n",
    "\n",
    "docker/mapping/Dockerfile\n",
    "```\n",
    "FROM continuumio/miniconda3:4.9.2\n",
    "RUN conda install -c conda-forge -y mamba==0.8.2\n",
    "RUN mamba install -c conda-forge -c bioconda -y \\\n",
    "        sra-tools==2.11.0 fastp==0.20.1 bowtie2==2.4.4 samtools==1.12  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-fields",
   "metadata": {},
   "source": [
    "## Commands and scripts to reproduce reads mapping\n",
    "\n",
    "```\n",
    "docker-compose run --rm mapping /bin/bash scripts/210615_1_Kim+20SciData.sh \n",
    "```\n",
    "\n",
    "scripts/210615_1_Kim+20SciData.sh:\n",
    "\n",
    "```{bash}\n",
    "#!/bin/bash -eu\n",
    "\n",
    "# reference genome indexing\n",
    "run_bowtie2build () {\n",
    "    local infile=$1\n",
    "    local outfile=${infile/reference/bowtie2_idx}\n",
    "    local logfile=${outfile/.fna/.log}\n",
    "    outfile=${outfile/.fna/}\n",
    "    \n",
    "    bowtie2-build $infile $outfile &> $logfile\n",
    "}\n",
    "\n",
    "export -f run_bowtie2build\n",
    "\n",
    "ls /data/expression/Kim+20SciData/reference/*.fna | xargs -t -P5 -L1 -I{} /bin/bash -c 'run_bowtie2build {}'\n",
    "\n",
    "# read mapping\n",
    "run_bowtie2align () {\n",
    "    local basename=/data/expression/Kim+20SciData\n",
    "    local readsfile=${basename/data/data\\/pubdata}/trimmed_fastq/$1.fastq.gz\n",
    "    local reffile=$basename/bowtie2_idx/$2\n",
    "    local outfile=$basename/bam/$1.bam\n",
    "    local logfile=$basename/bam/$1.log\n",
    "    bowtie2 --very-sensitive --no-unal -x $reffile -U $readsfile -p 8 2> $logfile | samtools view -b | samtools sort -o $outfile -@ 8\n",
    "}\n",
    "\n",
    "export -f run_bowtie2align\n",
    "\n",
    "tail -n +2 /metadata/expression/Kim+20SciData_runs.tsv | awk '{print $1,$12}' | xargs -t -P12 -L2 -I{} /bin/bash -c 'run_bowtie2align {}'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-devil",
   "metadata": {},
   "source": [
    "### Depth calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collective-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import tempfile\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from pyscripts.config import path2\n",
    "from pyscripts.datasets import DatasetLoader\n",
    "from pyscripts.genomeutil import get_intervaltree\n",
    "dloader = DatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "introductory-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = pd.read_csv(path2.metadata/'expression'/'Kim+20SciData_refs.tsv', sep='\\t')\n",
    "runs = pd.read_csv(path2.metadata/'expression'/'Kim+20SciData_runs.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excellent-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_intervals = {\n",
    "    ref: {\n",
    "        rec.id:\n",
    "        get_intervaltree(rec, filt_func=lambda feat: feat.type in {'rRNA', 'tRNA'})\n",
    "        for rec in dloader.load_genome(ref, path2.pubdata/'expression'/'Kim+20SciData'/'reference')\n",
    "    }\n",
    "    for ref in refs['reference_assembly']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twenty-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = path2.data/'expression'/'Kim+20SciData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alpha-trail",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98d62a693eb478e8db197129210ae84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calc_RNAseq_depth(tag):\n",
    "    # Note that the sense strand of reverse reads is + strand, while that of forward reads is - strand.\n",
    "    # This is due to library configuration.\n",
    "    itvs = ignore_intervals[runs.set_index('tag').loc[tag, 'reference_assembly']]\n",
    "    \n",
    "    with pysam.AlignmentFile(workdir/'bam'/f'{tag}.bam', 'rb') as inbam:\n",
    "        try:\n",
    "            _, plus_tmp  = tempfile.mkstemp(suffix='.bam')\n",
    "            _, minus_tmp = tempfile.mkstemp(suffix='.bam')\n",
    "\n",
    "            with pysam.AlignmentFile(plus_tmp , 'wb', template=inbam) as plus_bam, \\\n",
    "                 pysam.AlignmentFile(minus_tmp, 'wb', template=inbam) as minus_bam :\n",
    "                outbam = {True: plus_bam, False: minus_bam}\n",
    "                for read in inbam:\n",
    "                    # ignore unmapped or multi-mapped reads\n",
    "                    if read.is_unmapped or read.has_tag('XS'): \n",
    "                        continue\n",
    "                    # ignore reads that intersect with tRNA/rRNA on the same strand\n",
    "                    rrn, rrs, rre = read.reference_name, read.reference_start, read.reference_end\n",
    "                    if any((it.data.strand > 0) == read.is_reverse for it in itvs[rrn][rrs:rre]): \n",
    "                        continue\n",
    "\n",
    "                    outbam[read.is_reverse].write(read)\n",
    "\n",
    "            pos_idx = pd.MultiIndex.from_tuples([(ref, i) for ref, l in zip(inbam.references, inbam.lengths) for i in range(l)])\n",
    "\n",
    "            with pysam.AlignmentFile(plus_tmp, 'rb') as plus_bam:\n",
    "                depth_plus = pd.Series({\n",
    "                    (pc.reference_name, pc.reference_pos): pc.nsegments\n",
    "                    for pc in plus_bam.pileup()\n",
    "                }, index=pos_idx, dtype=pd.Int64Dtype()).fillna(0)\n",
    "\n",
    "            with pysam.AlignmentFile(minus_tmp, 'rb') as minus_bam:\n",
    "                depth_minus = pd.Series({\n",
    "                    (pc.reference_name, pc.reference_pos): pc.nsegments\n",
    "                    for pc in minus_bam.pileup()\n",
    "                }, index=pos_idx, dtype=pd.Int64Dtype()).fillna(0)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            os.remove(plus_tmp)\n",
    "            os.remove(minus_tmp)\n",
    "        \n",
    "    depth_plus.to_pickle(workdir/'depth'/f'{tag}.plus.pkl.bz2')\n",
    "    depth_minus.to_pickle(workdir/'depth'/f'{tag}.minus.pkl.bz2')\n",
    "\n",
    "with Pool(40) as pool:\n",
    "    for _ in tqdm(pool.imap_unordered(calc_RNAseq_depth, runs[runs['type']=='RNA']['tag']), total=40):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "common-shelf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d266a0d9b737450fb4cd6c667e4fed30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calc_Riboseq_density(tag):\n",
    "    # Contrary to RNA-Seq, for Ribo-Seq reads, the sense strand of forward reads is + strand, while that of reverse reads is - strand.\n",
    "    itvs = ignore_intervals[runs.set_index('tag').loc[tag, 'reference_assembly']]\n",
    "    \n",
    "    with pysam.AlignmentFile(workdir/'bam'/f'{tag}.bam', 'rb') as bamfile:\n",
    "        depth_plus  = {ref: pd.Series(0, index=range(l)) for ref, l in zip(bamfile.references, bamfile.lengths)}\n",
    "        depth_minus = {ref: pd.Series(0, index=range(l)) for ref, l in zip(bamfile.references, bamfile.lengths)}\n",
    "\n",
    "        for read in bamfile:\n",
    "            # ignore unmapped or multi-mapped reads\n",
    "            if read.is_unmapped or read.has_tag('XS'): \n",
    "                continue\n",
    "            # ignore reads that intersect with tRNA/rRNA on the same strand\n",
    "            rrn, rrs, rre = read.reference_name, read.reference_start, read.reference_end\n",
    "            if any((it.data.strand > 0) == read.is_reverse for it in itvs[rrn][rrs:rre]): \n",
    "                continue\n",
    "                \n",
    "            if read.is_reverse:\n",
    "                depth_minus[rrn][rrs] += 1\n",
    "            else:\n",
    "                depth_plus[rrn][rre-1] += 1\n",
    "\n",
    "        depth_plus  = pd.concat(depth_plus.values() , keys=depth_plus.keys() )\n",
    "        depth_minus = pd.concat(depth_minus.values(), keys=depth_minus.keys())\n",
    "        \n",
    "        depth_plus.to_pickle(workdir/'depth'/f'{tag}.plus.pkl.bz2')\n",
    "        depth_minus.to_pickle(workdir/'depth'/f'{tag}.minus.pkl.bz2')\n",
    "        \n",
    "with Pool(40) as pool:\n",
    "    for _ in tqdm(pool.imap_unordered(calc_Riboseq_density, runs[runs['type']=='Ribo']['tag']), total=40):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-active",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
